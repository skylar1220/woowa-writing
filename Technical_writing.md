# 리뷰미 서비스의 조회 성능 개선기

## 별로 안 느린데 성능 개선을 왜 해?
우리 서비스는 팀원에게 나의 협업 능력에 대한 리뷰를 받는 서비스입니다. 그럼 사용자가 ‘느린데? 불편한데?’ 라고 느낄 상황은 리뷰 조회 상황이 되겠네요. 하지만 지금까지 유저 테스트로 사용자들을 만났을 때, 또 우리끼리의 테스트에서 조회가 느리다고 느꼈던 적은 없었습니다.

그렇다면 성능 개선을 하지 않아도 될까요?
‘아직 우리 서비스가 크지 않고 현재 불편함을 느끼지 않으니 불편함을 느낄 때 개선을 하자!’
저희도 처음에는 이렇게 생각했습니다. 하지만 놓치고 있었던 것이 있었습니다. 바로 불확실성이었죠.

서비스가 점점 완성 되가면서 팀 내에서 이런 요구사항이 나오기 시작했습니다.
‘우테코 수료식이 점점 다가오니 서로에게 롤링 페이퍼를 써보는 이벤트를 만들어보자.’
‘우테코 7기 프리코스가 시작되니 서로 코드 리뷰를 해주는 사람들끼리 리뷰를 남길 수 있게 이벤트를 만들어보자.’
우테코 크루의 인원은 총 150명 내외입니다. 우테코 7기 프리코스 참여자는 작년 기준 4천명 내외일 것입니다. 최대의 상황을 가정해 이 인원이 모두 리뷰를 저장하고 조회한다면 사용자들은 어떤 경험을 하게될까요? 이 사용자들이 각자 10개씩 리뷰를 남기게 된다면 리뷰 조회 속도는 어떻게 될까요?

현재는 문제가 없지만 이렇게 4만건 이상의 리뷰가 DB에 쌓인다면 조회 성능에 문제가 생길 것이라는 건 어렵지 않게 추측할 수 있습니다. 이제 서비스를 바라보는 관점이 달라질 시점이 되었습니다. 오버 스펙을 준비하다는 걱정이 아닌, 자주 변화하는 서비스 규모, 이벤트에 유연하게 대처하기 위한 방법을 준비하는 단계에 다다른 것이죠.

그래서 우리는 ‘리뷰미 서비스를 이용하여 이벤트를 진행할 때’를 가정하고 대규모 사용자의 대규모 조회 상황에서 일어나는 문제 개선을 목표로 조회 성능 개선 작업을 시작했습니다.



## 1단계: 쿼리가 덜 나가는 코드
가장 간단히 할 수 있는 코드 레벨에서의 개선을 먼저 생각해보았습니다.
위의 화면을 만들기 위한 코드는 이렇습니다. 리뷰 목록을 조회하는 간단한 로직이죠?
```java
public List<ReviewDetailResponse> mapToReviewList(List<Review> reviews) {
   return reviews.stream()
           .map(review -> new ReviewDetailResponse(review.getTextAnswers())
           .toList();
}
  ```
리뷰를 반복하면서 리뷰 카드 응답 목록을 만든다.
각 리뷰 카드 응답 목록은 리뷰 객체에서 서술형 응답을 getter로 불러와서 만든다.

하지만 이 방식의 문제가 있었습니다. 자연스러운 생각의 흐름을 따라 짠 코드이기에 이해가 쉽지만, 나가는 쿼리의 양을 고려하지 않은 코드였던 것이죠. 위의 코드를 기반으로 리뷰 목록을 조회했을 때 나가는 쿼리는 다음과 같았습니다. (달린 리뷰 갯수는 10개를 가정하였습니다.)
- text_answer 테이블에서 review_id로 10회 조회
  text_answer 갯수만큼 쿼리가 발생하고 있네요. 그 이유를 알아보기 위해 Review 엔티티를 살펴보겠습니다.
```java
@Entity
public class Review {


   @OneToMany
   private List<TextAnswer> textAnswers;
}
```
원인이 여기있었네요. 여러개의 리뷰를 반복하며 `review.getTextAnswers()`을 실행하기 때문에 text_answer 테이블에서 review_id로 조회하는 쿼리가 리뷰 갯수만큼 발생하고 있었습니다.
만약 리뷰가 100개 달렸다면 100번의 조회 쿼리가 발생하겠죠? 개선이 필요해보입니다.

어떻게 하면 리뷰 갯수만큼 쿼리가 발생하는 게 아닌, 리뷰가 몇개가 달리든 한번의 쿼리만 발생하게 할 수 있을까요?

우리가 생각한 것은 review를 갖고 textAnswer를 그 때 그 때 조회하게 하는 책임을 DB에서 어플리케이션으로 올리는 것이었습니다. review에 해당하는 textAnswer 데이터를 어플리케이션으로 한번에 불러오는 것입니다.

그럼 한꺼번에 조회해온 textAnswer가 어떤 review에 해당하는지는 어떻게 구분할까요? 우리가 원하는 건 db를 통해 조회하는 것처럼 review 별로 textAnswer 데이터를 뽑아쓰는 것입니다. 그렇다면 해결방법으로 Map을 사용할 수 있겠네요. Review를 key로, textAnswer 데이터들을 value로 갖는 Map을 만들어서 db에서 불러온 textAnswer를 review별로 저장하는 방식입니다.
그렇다면 리뷰 별로 반복하여 textAnswer들을 뽑아 응답을 생성하더라도 쿼리를 발생시키지 않을 수 있겠네요. 대신 우리가 만든 Map에서 리뷰별로 textAnswer을 찾아쓰면 됩니다.
```java
public List<ReviewListElementResponse> mapToReviewList(List<Review> reviews) {
   Map<Review, List<TextAnswer>> textAnswers = textAnswerRepository.findByReviews(reviews)
           .stream()
           .collect(Collectors.groupingBy(TextAnswer::getReview));


   return reviews.stream()
           .map(review -> new ReviewListElementResponse(textAnswers.get(review)))
           .toList();
}
  ```
위의 코드를 실행시켜 볼까요? 이제 리뷰가 여러개 달린 리뷰 목록을 조회해도 이렇게 한 번의 쿼리만 발생하게 되었습니다.
```sql
SELECT text_answer.* FROM text_answer
JOIN review ON text_answer.review_id = review.id
WHERE review.id IN (1, 2, 3, 4, 5, 6, 7, 8, 9, 10);
```
직접 데이터를 넣어 응답 시간과 로딩된 데이터의 크기를 비교해볼까요?
100건의 리뷰 기준 기존의 로직과 개선한 로직의 차이는 아래와 같았습니다.
로컬 환경(H2)에서 테스트해본 결과이기때문에 실제 DB 통신을 생각해보면 더 큰 차이가 날 것이라고 예상할 수 있었습니다.

이렇게 코드 레벨에서의 쿼리를 덜나가게 하는 방식을 적용해보았습니다. 다음 단계로 가봅시다!



## 2단계: 인덱스
1단계에서는 코드에서 DB를 덜 호출하게 하는 로직으로 개선해보았습니다. 이제는 코드 레벨에서 DB 쪽으로 눈을 돌려봅시다. DB에서 일어나는 작업에서 성능을 개선하는 방법은 없을까요?

문제 상황을 가정해보면 개선 방법을 생각해내는데 도움이 될 것 같습니다. 앞에서 이야기한 상황을 다시 가져와볼까요?

문제 상황: 우테코 7기 프리코스 시작. 서로 코드 리뷰를 주고받을 프리코스 참가자들에게 서로의 코드 리뷰에 대해 상호 평가하는 목적으로 리뷰미 서비스를 제공
사용 인원: 최대 5000명 내외
저장되는 데이터양: 인당 20명에게 리뷰를 받는다고 가정했을 때 100,000개의 리뷰 데이터 저장

> 리뷰미의 review 테이블 구조 간단 설명
>
사용자는 리뷰그룹(review_group)을 생성합니다.
리뷰그룹을 상대에게 공유합니다.
상대가 리뷰그룹에 들어가 리뷰를 작성하면 review 테이블에 해당 리뷰그룹 id를 갖는 review 데이터가 추가됩니다.

만약 10만건의 데이터가 있는 review 테이블에서 내 리뷰그룹 id를 통해 내가 받은 리뷰를 조회하려고 한다면 어떤 작업이 일어날까요?
조회 조건: 내 리뷰그룹 id = 2, 예상 조회 결과는 12건
아마 review_group_id = 2인 row을 찾기위해 10만개의 row를 스캔하는 과정이 일어날 것입니다.
과연 이 조회는 얼마나 걸릴까요? review 테이블에 10만건의 데이터를 넣고 실행결과를 확인해봅시다.

```sql
-> Filter: (r.review_group_id = 2)  
(cost=10094 rows=10006)  (actual time=0.075..39.1 rows=12 loops=1) 
-> Table scan on r  
(cost=10094 rows=100058)  (actual time=0.0621..33 rows=100137 loops=1)
```

실행 결과를 해석해볼까요?
- Table scan 단계
    - 순서 상 Filter보다 먼저 일어남
    - 테이블에 대한 전체 스캔을 실행했다.
    - 실행 계획 : 100,058 개의 row를 스캔하는 데 10,094의 비용이 들 것으로 예상했다.
    - 실행 결과 : 100,137 개의 행을 스캔했으며, 33밀리초(0.033초)가 소요되었고, 1번 실행되었다.
- Filter 단계
    - 스캔한 row 중에서 review_group_id = 2 조건에 맞는 행을 필터링 한다.
    - 실행 계획 : 10,006개의 row 가 해당할 것으로 예상하고, 스캔하는 데 10,094 의 비용이 들 것으로 예상했다.
    - 실행 결과 : 12개의 행을 찾았고, 총 39.1밀리초(0.0391초)가 소요되었다.

‘별로 오래 안 걸리는데?’ 라고 생각이 들 수 있습니다. 그렇다면 상황을 다시 가정해볼까요?

우테코 프리코스의 미션은 보통 4개로 이루어져있습니다. 하지만 이번 기수에 미션이 갑자기 늘어난다면 어떻게 될까요? 넉넉하게 미션이 10개로 늘어났다고 가정한다면 현재 10만개의 데이터가 10번 쌓이는, 즉 100만건의 데이터를 저장하는 상황이 발생하겠네요. 과연 100만건의 데이터일 때는 리뷰 목록 조회가 얼마나 걸릴까요?  이번엔 review 테이블에 100만건의 데이터를 넣고 실행결과를 확인해봅시다.

```sql
-> Filter: (r.review_group_id = 56) 
(cost=107773 rows=10.3) (actual time=0.0674..1387 rows=12 loops=1) 
-> Table scan on r (cost=107773 rows=1.07e+6) 
(actual time=0.0555..1320 rows=1.1e+6 loops=1)
```
- Table scan 단계: 1,100,000개의 행을 스캔했으며, 1320밀리초(1.32초)가 소요되었다.
- Filter 단계 : 12개의 행을 찾았고, 총 1387밀리초(1.387초)가 소요되었다.

이번엔 쿼리를 실행하는데 1.387초가 걸렸네요. 이건 쿼리만 실행한 결과이니, API 통신과 다른 비즈니스 로직이 포함되면 사용자가 실제로 느끼는 시간은 더 걸릴 거예요.

사용자 경험 연구 기관 Nielsen Norman Group에 따르면 사용자는 어떤 작업을 수행하는 데 걸리는 시간이 0.1초 이하인 경우 사용 경험이 좋다고 평가한다고 합니다. 반면 1초 이상 걸리는 경우 이를 지연이라고 인식하고 사용자의 흐름이 방해받는다고 말합니다.

내가 받은 리뷰 목록을 조회하는 데 2초 내외가 걸리는 서비스라… 이번엔 분명 개선이 필요해보입니다.

이제 요구 사항이 명확해졌습니다.
```
1. 문제 상황: 100만건 내외의 데이터에서 10개 정도의 결과를 가지는 조회에 1초 이상이 소요된다.
2. 목표: 쿼리 실행 시간을 0.1초 이하로 단축시킨다.
3. 원인 분석: Table scan 단계의 실행 결과를 보면 알 수 있다시피, 100만개의 row를 모두 스캔하는 과정에 많은 시간이 소요된다.
```
어떻게 하면 스캔하는 row의 수를 줄일 수 있을까요? 이 때 사용할 수 있는 것이 바로 인덱스입니다.


> **인덱스란?**  
> 칼럼의 값과 해당 레코드가 저장된 주소를 key -value로 삼아 인덱스로 만들어 두는 것을 이야기합니다. 이 칼럼의 값들은 주어진 순서로 미리 정렬하여 보관하기 때문에 모든 데이터를 스캔하지 않고도 비교적 빠르게 원하는 데이터를 찾아갈 수 있습니다.

그럼 review 테이블에 review_group_id 칼럼에 인덱스를 추가한다면 더 빠르게 리뷰를 찾을 수 있으니  인덱스를 추가하면 되겠네요. 하지만 인덱스를 추가하기 전에 우리가 고려해야할 점들이 있습니다.
바로, 인덱스를 추가했을 때 발생하는 오버헤드입니다.

1. 공간 사용: 인덱스는 추가적인 데이터 구조이기 때문에 디스크 공간을 더 차지합니다.
2. 인덱스 업데이트 비용: 데이터를 삽입, 수정, 삭제할 때 인덱스도 함께 업데이트해야 합니다. 이 때 추가적인 시간과 자원이 들게됩니다.
3. 인지 부담: 인덱스가 있는 경우 해당 컬럼과 관련된 추가적인 쿼리를 작성할 때 인덱스로 인해 일어날 성능 영향을 매번 인지하고 고려해야합니다.

이렇게 인덱스 추가에도 리소스가 발생하므로, 인덱스가 성능 개선에 크게 영향을 미치지 않거나, 또는 성능에 문제를 일으키는 경우를 피해서 인덱스를 적용해야겠네요. 그렇다면 어떤 기준으로 인덱스를 추가해야할까요? 우리는 아래와 같은 기준을 세웠습니다.

1. Cardinality가 높은가
- Cardinality란? 해당 칼럼에 있는 고유한 값의 수
- Cardinality가 높으면 인덱스를 통해 불필요한 데이터를 걸러낼 수 있기 때문에 속도가 빨라집니다.
- 반대로 성별과 같이 중복된 값이 많은 경우(낮은 Cardinality) 인덱스를 통해 찾는 것 보다 풀 스캔 방식이 더 빠를 수 있기 때문에 인덱스를 설정하지 않는 것이 더 효율적입니다.
2. 조회 시 where, order by절에 자주 사용되는 컬럼인가
- 조건문에 사용되는 컬럼을 인덱스로 사용할 수 있으나, 자주 사용되어 조회 활용도가 높아야 인덱스 활용 가치가 높습니다.
3. insert, update, delete가 자주 발생하지 않는가
- 테이블에 변경이 있을 때마다 인덱스도 변경해주어야 하기 때문에 변경이 잦은 테이블에 인덱스가 많아진다면 성능 저하가 올 수 있습니다.
- 따라서 조회가 잦더라도, 데이터 수정이 많다면 인덱스를 설정하는 것이 적절한지 생각해봐야 합니다.
4. 테이블 규모가 큰가
- 테이블 규모가 크지 않다면 풀스캔과 크게 성능 차이가 나지 않을 수 있습니다.

인덱스의 부작용도 알았고, 적용 기준도 세웠으니 다시 문제 상황으로 돌아와봅시다.

```
1. 문제 상황: 100만건 내외의 review 데이터에서 10개 정도의 결과를 가지는 review_group_id를 통한 조회에 1초 이상이 소요된다.
2. 목표: 쿼리 실행 시간을 0.1초 이하로 단축시킨다.
3. 원인 분석: Table scan 단계의 실행 결과를 보면 알 수 있다시피, 100만개의 row를 모두 스캔하는 과정에 많은 시간이 소요된다.
4. (NEW) 해결 방법: review_group_id 칼럼에 인덱스를 추가해 스캔 대상을 10개로 줄인다.
```

앞에서 세운 기준에 따라 인덱스 추가가 적절한 칼럼인지 점검해봅시다.

100만건의 리뷰 테이블에 리뷰 20개당 한 개의 리뷰 그룹을 가진다고 했을 때, 5만개의 unique한 리뷰 그룹이 존재하므로 Cardinality가 매우 높습니다.
review_group_id를 조건으로 리뷰 목록을 조회하는 상황은 매우 자주 발생합니다.
리뷰가 등록되는 경우, 즉 insert도 자주 발생하나, 일반적인 웹과 서비스 특성상 쓰기 보다 읽기 비율이 훨씬 많기 때문에 조회에서의 효율을 선택했습니다.
테이블 규모가 매우 큽니다.

인덱스 추가 기준에 모두 적합하네요. 마음 편히 인덱스를 추가해도 되겠습니다. 그럼 인덱스를 적용한 후의 실행 결과를 확인해볼까요?
```sql
-> Index lookup on r using review_idx_review_group_id (review_group_id=2) 
(cost=5 rows=12) (actual time=3.36..3.36 rows=12 loops=1)
```
- 인덱스 적용시 결과: 12개의 행을 스캔했으며, 3.36밀리초(0.00336초)가 소요되었다.
- 인덱스 미적용시 결과: 1,100,000개의 행을 스캔했으며, 1320밀리초(1.32초)가 소요되었다.

100만개의 row를 스캔하며 1.32초가 걸리던 인덱스 미적용시와 달리, 인덱스를 적용한 후에는 12개의 row만을 스캔하여 0.00336초라는 실행 시간이 걸렸습니다. 무려 99.75%의 시간이 감소하는 결과를 얻을 수 있었네요.

이렇게 DB에서 인덱스를 적용하여 조회 성능을 개선해보았습니다.

## 정리 및 추가 계획
지금까지 대규모 데이터의 조회 상황에서의 문제를 해결하기 위한 여러 방법에 대해 알아보았습니다.
가상의 상황 설정과 구체적인 목표 수치 설정 후 코드 레벨, DB 레벨 등 여러 측면에서의 접근을 통해 여러 방법을 적용해볼 수 있었습니다.

이번엔 리뷰 목록 조회라는 클라이언트에게 전달되는 값이 고정되어있지 않은 상황에 대한 조회 성능 개선 방법을 알아보았지만, 추가로 클라이언트에게 전달되는 값이 고정된 경우도 있을 수 있겠네요. 우리의 서비스에서는 리뷰 작성 폼이 그 예가 되겠습니다. 이런 경우에는 또 어떤 방법으로 조회 성능을 개선할 수 있을지 메모리 캐싱, 조회 전용 엔티티 등의 방법을 계획해보려고 합니다. 

